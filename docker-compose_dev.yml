version: "3"

services:
  mysqlsrv:
    image: mysql:5.7
    container_name: mongo
    environment:
      MYSQL_ROOT_PASSWORD: "12345678"
      MYSQL_DATABASE: "mydb"
    ports:
      - "3306:3306"
    volumes:
      - ./MySql:/var/lib/mysql
    networks:
      - data-master

  hadoop:
    build: images/hadoop
    container_name: hadoop-env
    restart: always
    ports:
      - 8088:8088 
      - 50070:50070
      - 9000:9090
      - 9870:9870
      - 8020:8020
    volumes:
      - ./scripts:/scripts
      - ./raw-data:/raw-data
      - ./hdfs:/opt/hadoop/hdfs
    env_file:
      - images/hadoop/.env
    user: root
    networks: 
      - data-master

  mongo:
    image: mongo
    container_name: mongo
    ports:
      - 27017:27017
    restart: unless-stopped
    environment:
        MONGO_INITDB_ROOT_USERNAME: "root"
        MONGO_INITDB_ROOT_PASSWORD: "12345678"
    networks: 
      - data-master
        
  jupyter_lab:
    container_name: jupyter_lab
    image: jupyter/pyspark-notebook:python-3.8.8
    ports:
      - "8888:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=easy
    volumes:
      - .:/home/jovyan/work
    networks:
      - data-master
  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.0
    restart: always
    container_name: zookeeper
    networks: 
      - data-master
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: confluentinc/cp-kafka:6.2.0
    restart: always
    container_name: kafka
    networks: 
      - data-master
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1

      
  python-stream:
    build: images/python-stream
    container_name: python-stream
    restart: always
    networks: 
      - data-master
    depends_on:
      - kafka
      - zookeeper

  spark-stream:
    build: images/spark-stream
    container_name: spark-stream
    restart: always
    networks: 
      - data-master
    depends_on:
      - python-stream
      - kafka

  kafdrop:
    image: obsidiandynamics/kafdrop:3.27.0
    restart: always
    container_name: kafkadrop
    networks: 
      - data-master
    depends_on:
      - kafka
    ports:
      - 19000:9000
    environment:
      - KAFKA_BROKERCONNECT=kafka:29092
  elasticsearch:
    container_name: elastic
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.0
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      discovery.type: "single-node"
      ELASTIC_USERNAME: elastic
      ELASTIC_PASSWORD: "abcde"
      ES_JAVA_OPTS: "-Xms2g -Xmx2g"
    networks:
      - data-master
    volumes:
      - ./esdata:/usr/share/elasticsearch/data
      
  kibana:
    image: docker.elastic.co/kibana/kibana:7.12.0
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_USERNAME: elastic
      ELASTICSEARCH_PASSWORD: "abcde"
    depends_on:
      - elasticsearch
    networks:
      - data-master

volumes:
  esdata:
    driver: local
  hdfs:
    driver: local
  database-data:

networks:
  data-master:
    driver: bridge
